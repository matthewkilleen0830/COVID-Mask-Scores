{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "# possibly more than needed\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "import chardet\n",
    "import gmaps\n",
    "\n",
    "# Import API key\n",
    "from api_keys import g_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of column/headers for Great Big Dataframe (GBDf) with empty cells\n",
    "\n",
    "# FIPS\n",
    "# (five-digit code: the first two represent state, the last three represent county in that state)\n",
    "\n",
    "# County\n",
    "# (name, e.g. Jackson County in many states, but also Orleans Parish of Louisiana, or the Aleutians East Borough of Alaska)\n",
    "\n",
    "# State (name)\n",
    "\n",
    "# Pop\n",
    "# (2019 county population estimate)\n",
    "\n",
    "# PopDens\n",
    "# (Population density; derived from county 2019 population estimate divided by county land mass in another dataframe)\n",
    "\n",
    "# MskScore\n",
    "# (Mask-wearing score derived from pct in each county who said never, rarely sometimes, frequently, always wear a mask when going out)\n",
    "\n",
    "# CaseRate\n",
    "# (cumulative COVID cases per 100,000 population by county January 21–July 14, 2020)\n",
    "\n",
    "# DeathRate\n",
    "# (cumulative COVID deaths per 100,000 population by county January 21–July 14, 2020)\n",
    "\n",
    "# Income\n",
    "# (Mean per-capita income by county; this is a bonus-round question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt's code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Census 2010-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. US Census 2010-2019\n",
    "censusDataReadMeURL = \"https://www.census.gov/data/tables/time-series/demo/popest/2010s-counties-total.html\"\n",
    "\n",
    "# This is where the census data .CSV lives locally...:\n",
    "censusDataFilepath = \"Resources/co-est2019-alldata_exp.csv\"\n",
    "\n",
    "print(f\"{censusDataFilepath} is {round(os.path.getsize(censusDataFilepath)/1024/1024, 2)} megabytes (MB).\\nMore info here:\\n{censusDataReadMeURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into censusData DataFrame\n",
    "censusData = pd.read_csv(censusDataFilepath, encoding=\"iso-8859-1\")\n",
    "censusData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. COVID-19 cases\n",
    "caseDataReadMeURL = \"https://github.com/nytimes/covid-19-data/blob/master/README.md\"\n",
    "\n",
    "# This is where the .CSV lives locally...:\n",
    "caseDataFilepath = \"Resources/us-counties.csv\"\n",
    "\n",
    "print(f\"The file at {caseDataFilepath} is {round(os.path.getsize(caseDataFilepath)/1024/1024, 2)} MB.\\nMore info here:\\n{caseDataReadMeURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into caseData DataFrame\n",
    "caseData = pd.read_csv(caseDataFilepath, encoding = \"UTF-8\")\n",
    "caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing NaN values (caseData's \"unknown\" counties)\n",
    "caseData.dropna(axis = 0, how = \"any\", thresh = None, subset = None, inplace = True)\n",
    "caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert caseData FIPS values from float to int\n",
    "caseData.fips = caseData.fips.astype(np.int64)\n",
    "caseData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge caseData and censusData DataFrames\n",
    "merged_caseData = pd.merge(censusData, caseData, how = \"outer\", left_on = \"FIPS\", right_on = \"fips\", on = None, sort = False, copy = True, indicator = False, validate = None)\n",
    "merged_caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate and/or irrelevant columns\n",
    "merged_caseData.drop(columns = [\"FIPS\", \"STATE\", \"COUNTY\", \"STNAME\", \"CTYNAME\", \"CENSUS2010POP\"], inplace = True)\n",
    "merged_caseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add population to row 3142 (New York City aggregate)\n",
    "merged_caseData[\"POPESTIMATE2019\"][3142] = 8336817\n",
    "merged_caseData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns\n",
    "organized_caseData = merged_caseData[[\"date\", \"fips\", \"county\", \"state\", \"POPESTIMATE2019\", \"cases\", \"deaths\"]]\n",
    "organized_caseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "renamed_caseData = merged_caseData.rename(columns = {\"date\":\"Date\", \"fips\":\"FIPS\", \"county\":\"County\", \"state\":\"State\",\n",
    "                                                     \"POPESTIMATE2019\":\"PopEst\", \"cases\":\"Cases\", \"deaths\":\"Deaths\"})\n",
    "renamed_caseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns\n",
    "reorganized_caseData = renamed_caseData[[\"Date\", \"FIPS\", \"County\", \"State\", \"PopEst\", \"Cases\", \"Deaths\"]]\n",
    "reorganized_caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due diligence to check DataFrame for rows with missing data\n",
    "reorganized_caseData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing no data and reset index\n",
    "complete_caseData = reorganized_caseData.dropna(axis = 0, how = \"any\", thresh = None, subset = None, inplace = False)\n",
    "complete_caseData = complete_caseData.reset_index()\n",
    "complete_caseData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame containing (4) boroughs of New York (Manhattan dropped out on execution of previous cell) so the\n",
    "# population data is not counted twice\n",
    "droppedNYData = complete_caseData.loc[(complete_caseData[\"State\"] == \"New York\") & (complete_caseData[\"Cases\"] == 0), :]\n",
    "droppedNYData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove droppedNYData DataFrame from complete_caseData DataFrame and reset index\n",
    "final_caseData_index = droppedNYData.index\n",
    "final_caseData = complete_caseData.drop(final_caseData_index, inplace = False)\n",
    "final_caseData = final_caseData.reset_index()\n",
    "final_caseData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate and/or irrelevant columns\n",
    "final_caseData.drop(columns = [\"level_0\", \"index\"], inplace = True)\n",
    "final_caseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_caseData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert final_caseData FIPS values from float to int\n",
    "final_caseData.FIPS = final_caseData.FIPS.astype(np.int64)\n",
    "final_caseData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Landmass Data (by County)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Landmass (and thence population density)\n",
    "landMassDataReadMeURL = \"https://hub.arcgis.com/datasets/48f9af87daa241c4b267c5931ad3b226_0/data?orderBy=FIPS\"\n",
    "# This is where the land mass data .CSV lives locally...:\n",
    "landMassDataFilepath = \"Resources/counties-by-land-area.csv\"\n",
    "\n",
    "print(f\"{landMassDataFilepath} is {round(os.path.getsize(landMassDataFilepath)/1024/1024, 2)} MB.\\nMore info here:\\n{landMassDataReadMeURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into landmassData DataFrame\n",
    "landmassData = pd.read_csv(landMassDataFilepath)\n",
    "landmassData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "landmassData = landmassData.reset_index()\n",
    "landmassData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to sort landmassData by FIPS code\n",
    "a = landmassData[[\"FIPS\", \"FID\", \"NAME\", \"STATE_NAME\", \"STATE_NAME\", \"POPULATION\", \"SQMI\"]]\n",
    "a = a.sort_values(by = \"FIPS\").reset_index().drop(columns = [\"index\"])\n",
    "a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to sort final_caseData by FIPS code\n",
    "b = final_caseData[[\"Date\", \"FIPS\", \"County\", \"State\", \"Cases\", \"Deaths\"]]\n",
    "b = b.sort_values(by = \"FIPS\").reset_index().drop(columns = [\"index\"])\n",
    "b.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert final_caseData FIPS values to integer and verify data types\n",
    "b[\"FIPS\"] = b[\"FIPS\"].astype(int)\n",
    "b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify landmassData data types\n",
    "a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify last row's index number\n",
    "b.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference in rows between final_caseData and landmassData DataFrames to identify Puerto Rico and\n",
    "# other non-U.S. \"counties\" we do not have case data for\n",
    "len(a) - len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to hold duplicate county's case data\n",
    "c = b[b[\"FIPS\"] == 2016]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to hold duplicate county's census data\n",
    "d = a[a[\"FIPS\"] == 2016]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames to create one entry for duplicate county\n",
    "final_merged_caseData = b.merge(a, how = \"left\", on = \"FIPS\")\n",
    "final_merged_caseData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify merge was successful\n",
    "check = final_merged_caseData[final_merged_caseData[\"FIPS\"] == 2016]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final_merged_caseData DataFrame to verify we have 3132 rows (including New York City aggregate)\n",
    "final_merged_caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate and/or irrelevant columns\n",
    "final_merged_caseData.drop(columns = [\"FID\", \"NAME\", \"STATE_NAME\", \"STATE_NAME\"], inplace = True)\n",
    "final_merged_caseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add population and landmass data to row 3132 (New York City aggregate) and verify\n",
    "final_merged_caseData[\"POPULATION\"][3131] = 8336817\n",
    "final_merged_caseData[\"SQMI\"][3131] = 302.06\n",
    "final_merged_caseData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "final_merged_caseData = final_merged_caseData.rename(columns = {\"POPULATION\":\"PopEst\"})\n",
    "final_merged_caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create per 100,000 people divisor\n",
    "perHundredK_divisor = final_merged_caseData[\"PopEst\"] / 100000\n",
    "\n",
    "# Calculate cases per 100,000\n",
    "casesPerHundredK = final_merged_caseData[\"Cases\"] / perHundredK_divisor\n",
    "\n",
    "# Calculate deaths per 100,000\n",
    "deathsPerHundredK = final_merged_caseData[\"Deaths\"] / perHundredK_divisor\n",
    "\n",
    "# Calculate population density\n",
    "popDens = final_merged_caseData[\"PopEst\"] / final_merged_caseData[\"SQMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to hold case rates and death rates (per 100,000 people), and population density\n",
    "final_merged_caseData[\"CaseRate\"] = casesPerHundredK\n",
    "final_merged_caseData[\"DeathRate\"] = deathsPerHundredK\n",
    "final_merged_caseData[\"PopDens\"] = popDens\n",
    "final_merged_caseData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize columns\n",
    "reorganized_final_merged_caseData = final_merged_caseData[[\"Date\", \"FIPS\", \"County\", \"State\", \"SQMI\", \"PopEst\", \"PopDens\",\n",
    "                                                           \"Cases\", \"CaseRate\", \"Deaths\", \"DeathRate\"]]\n",
    "reorganized_final_merged_caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort on DeathRate (or CaseRate) to find best/worst counties (for screenshot image)\n",
    "# reorganized_final_merged_caseData = reorganized_final_merged_caseData.sort_values(\"DeathRate\", ascending=False)\n",
    "# reorganized_final_merged_caseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reorganized_final_merged_caseData FIPS and Population values from float to int\n",
    "reorganized_final_merged_caseData.FIPS = reorganized_final_merged_caseData.FIPS.astype(np.int64)\n",
    "reorganized_final_merged_caseData.PopEst = reorganized_final_merged_caseData.PopEst.astype(np.int64)\n",
    "reorganized_final_merged_caseData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. County Geographic Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. County Centers (by geographic center latitude and longitude)\n",
    "countyCenterDataReadMeURL = \"https://github.com/btskinner/spatial/blob/master/data/county_centers.csv\"\n",
    "\n",
    "# This is where the county center data .CSV lives locally...:\n",
    "countyCenterDataFilepath = \"Resources/county_centers.csv\"\n",
    "\n",
    "print(f\"{countyCenterDataFilepath} is {round(os.path.getsize(countyCenterDataFilepath)/1024/1024, 2)} MB.\\nMore info here:\\n{countyCenterDataReadMeURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into countyCenterData DataFrame\n",
    "countyCenterData = pd.read_csv(countyCenterDataFilepath)\n",
    "countyCenterData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge countyCenterData with reorganized_final_merged_caseData to create heatmap DataFrame\n",
    "heatmapData = pd.merge(reorganized_final_merged_caseData, countyCenterData, how = \"left\", left_on = \"FIPS\", right_on = \"fips\", on = None, sort = False, copy = True, indicator = False, validate = None)\n",
    "heatmapData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate and/or irrelevant columns\n",
    "heatmapData.drop(columns = [\"fips\", \"clon00\", \"clat00\", \"pclon00\", \"pclat00\", \"pclon10\", \"pclat10\"], inplace = True)\n",
    "heatmapData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "heatmapData = heatmapData.rename(columns = {\"clon10\":\"Longitude\", \"clat10\":\"Latitude\"})\n",
    "heatmapData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns\n",
    "heatmapData = heatmapData[[\"Date\", \"FIPS\", \"County\", \"State\", \"SQMI\", \"PopEst\", \"PopDens\",\n",
    "                           \"Cases\", \"CaseRate\", \"Deaths\", \"DeathRate\", \"Latitude\", \"Longitude\"]]\n",
    "heatmapData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due diligence to check for missing data\n",
    "heatmapData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add missing latitude and longitude coordinates:\n",
    "\n",
    "# Kusilvak Census Area (Alaska)\n",
    "heatmapData[\"Latitude\"][81] = 62.09\n",
    "heatmapData[\"Longitude\"][81] = -163.53\n",
    "\n",
    "# Oglala Lakota Census Area (South Dakota)\n",
    "heatmapData[\"Latitude\"][2404] = 43.33\n",
    "heatmapData[\"Longitude\"][2404] = -102.55\n",
    "\n",
    "# New York City Aggregate (New York)\n",
    "heatmapData[\"Latitude\"][3131] = 40.7420\n",
    "heatmapData[\"Longitude\"][3131] = -73.9073\n",
    "\n",
    "heatmapData.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. COVID-19 Cases per 100,000 People on July 14, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access maps with unique API key\n",
    "gmaps.configure(api_key = g_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for CaseRate\n",
    "\n",
    "# Store latitude and longitude in locations\n",
    "locations = heatmapData[[\"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# Convert case rates to float\n",
    "caseRate = heatmapData[\"CaseRate\"].astype(float)\n",
    "\n",
    "# Plot Heatmap (U.S. geographic center is 39.8333, -98.5855)\n",
    "fig = gmaps.figure(zoom_level = 4.1, center = (37.8, -98.6))\n",
    "\n",
    "# Set max intensity to highest case rate found in the dataset\n",
    "max_intensity = heatmapData[\"CaseRate\"].max()\n",
    "\n",
    "# Create heat layer\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights = caseRate, \n",
    "                                 dissipating = False, max_intensity = max_intensity,\n",
    "                                 point_radius = 1.2, gradient = ['white', 'red'])\n",
    "\n",
    "\n",
    "\n",
    "# Add layer\n",
    "fig.add_layer(heat_layer)\n",
    "\n",
    "# Display figure\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. COVID-19 Deaths per 100,000 People on July 14, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for DeathRate\n",
    "\n",
    "# Store latitude and longitude in locations\n",
    "locations = heatmapData[[\"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# Convert death rates to float\n",
    "deathRate = heatmapData[\"DeathRate\"].astype(float)\n",
    "\n",
    "# Plot Heatmap (U.S. geographic center is 39.8333, -98.5855)\n",
    "fig = gmaps.figure(zoom_level = 4.1, center = (37.8, -98.6))\n",
    "\n",
    "# Set max intensity to mean death rate found in the dataset\n",
    "max_intensity = heatmapData[\"DeathRate\"].max()\n",
    "\n",
    "# Create heat layer\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights = deathRate, \n",
    "                                 dissipating = False, max_intensity = max_intensity,\n",
    "                                 point_radius = 0.8, gradient = ['white', 'red'])\n",
    "\n",
    "# Add layer\n",
    "fig.add_layer(heat_layer)\n",
    "\n",
    "# Display figure\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emerson's code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Mask-Wearing Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. mask-wearing survey\n",
    "maskWearingDataReadMeURL = \"https://github.com/nytimes/covid-19-data/blob/master/README.md\"\n",
    "# This is where the census data .CSV lives locally...:\n",
    "maskWearingDataFilepath = \"Resources/mask-use-by-county-exp.csv\"\n",
    "\n",
    "print(f\"{maskWearingDataFilepath} is {round(os.path.getsize(maskWearingDataFilepath)/1024/1024, 2)} MB.\\nMore info here:\\n{maskWearingDataReadMeURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskWearingData = pd.read_csv(maskWearingDataFilepath)\n",
    "maskWearingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskWearingData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "divisions = 5\n",
    "interval = scale / (divisions-1)\n",
    "print(f\"This will use the results of the NYT survey to score each county on a scale from 0 to {scale} where\")\n",
    "print(f\"never = 0\")\n",
    "print(f\"rarely = {interval}\")\n",
    "print(f\"sometimes = {interval*2}\")\n",
    "print(f\"frequently = {interval*3}\")\n",
    "print(f\"always = {interval*4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskWearingScore = rarely*interval + sometimes*interval*2 + frequently*interval*3 + always*interval*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in mask use by county csv file\n",
    "file_to_load = \"Resources/mask-use-by-county-exp.csv\"\n",
    "mask_counties = pd.read_csv(file_to_load)\n",
    "mask_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of counties \n",
    "total_counties = mask_counties[\"COUNTYFP\"].nunique()\n",
    "total_counties_df = pd.DataFrame([total_counties], columns = [\"Total Counties\"])\n",
    "total_counties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Never- Mask \n",
    "# never_mask = mask_counties[\"NEVER\"].apply(percentages_to_floats).mean()\n",
    "# never_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentages_to_floats(percentage):\n",
    "    string = percentage[0:-1]\n",
    "    return float(string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Never - Mask \n",
    "never_mask = mask_counties[\"NEVER\"].apply(percentages_to_floats).mean()\n",
    "never_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Rarely - Mask \n",
    "rarely_mask = mask_counties[\"RARELY\"].apply(percentages_to_floats).mean()\n",
    "rarely_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Sometimes - Mask \n",
    "sometimes_mask = mask_counties[\"SOMETIMES\"].apply(percentages_to_floats).mean()\n",
    "sometimes_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Frequently - Mask \n",
    "frequently_mask = mask_counties[\"FREQUENTLY\"].apply(percentages_to_floats).mean()\n",
    "frequently_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Always - Mask \n",
    "always_mask = mask_counties[\"ALWAYS\"].apply(percentages_to_floats).mean()\n",
    "always_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of mask wearing mean percentages\n",
    "summary_of_mask_usage_df = pd.DataFrame({\"NEVER\": [never_mask], \n",
    "                                        \"RARELY\": [rarely_mask], \n",
    "                                        \"SOMETIMES\": [sometimes_mask], \n",
    "                                        \"FREQUENTLY\": [frequently_mask], \n",
    "                                        \"ALWAYS\": [always_mask]})\n",
    "\n",
    "\n",
    "print(summary_of_mask_usage_df)\n",
    "# summary_of_mask_usage_df.style.format(\"{:.1%}\")\n",
    "pd.options.display.float_format = '{:,.2f}%'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# updated mask score to include never, rarely, sometimes, frequently & always based on a 0, 2.5, 5, 7.5, 10 scale \n",
    "mask_counties[\"Mask Score\"] = mask_counties[\"NEVER\"].apply(percentages_to_floats) * 0 + mask_counties[\"RARELY\"].apply(percentages_to_floats) * 2.5 + mask_counties[\"SOMETIMES\"].apply(percentages_to_floats) * 5.0 + mask_counties[\"FREQUENTLY\"].apply(percentages_to_floats) *7.5 + mask_counties[\"ALWAYS\"].apply(percentages_to_floats) *10 \n",
    "mask_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive \n",
    "mask_counties[\"Mask Score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in us-counties-csv in order to tick & tie the fips to the state names, and then start connecting to the mask score\n",
    "counties = pd.read_csv(caseDataFilepath).dropna()\n",
    "counties[\"fips\"] = counties[\"fips\"].apply(int)\n",
    "counties = counties[[\"state\", \"fips\"]]\n",
    "counties = counties.rename({\n",
    "    \"fips\": \"COUNTYFP\"\n",
    "},axis = 1)\n",
    "counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes in order to get Mask Score to align with state \n",
    "merged_df = mask_counties.merge(counties)\n",
    "merged_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask score sorted highest to lowest\n",
    "merged_df = merged_df.sort_values(\"Mask Score\", ascending = False)\n",
    "merged_df \n",
    "\n",
    "# is there a connection between a higher or lower mask score based on location? Perhaps the geo map can provide additional info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = merged_df[\"state\"]\n",
    "y_values = merged_df[\"Mask Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x_values, y_values)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Mask Wearing Scores by State on July 14, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created bar chart to demonstrate visual of mask score \n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "ax.barh(x_values, y_values, color = \"royalblue\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xticks(fontsize = 10)\n",
    "ax.set_title(\"Mask Score\\nby state as of July 14, 2020\", fontsize = 18)\n",
    "plt.xlabel(\"Mask Score\", fontsize = 14)\n",
    "# plt.ylabel(\"State\", fontsize = 14)\n",
    "# ax.grid()\n",
    "plt.savefig(\"MaskWearingScoresByState.png\")\n",
    "plt.xlim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Mask Wearing Scores by County on July 14, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge heatmapData and merged_df\n",
    "maskHeatMap = pd.merge(heatmapData, merged_df, how = \"left\", left_on = \"FIPS\", right_on = \"COUNTYFP\", on = None,\n",
    "                       sort = False, copy = True, indicator = False, validate = None)\n",
    "maskHeatMap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for Mask Score\n",
    "\n",
    "# Store latitude and longitude in locations\n",
    "locations = maskHeatMap[[\"Latitude\", \"Longitude\"]]\n",
    "\n",
    "# Convert mask scores to float\n",
    "mask_score = maskHeatMap[\"Mask Score\"].astype(float)\n",
    "\n",
    "# Plot Heatmap (U.S. geographic center is 39.8333, -98.5855)\n",
    "fig = gmaps.figure(zoom_level = 4.1, center = (37.8, -98.6))\n",
    "\n",
    "# Set max intensity to max mask score found in the dataset\n",
    "max_intensity = merged_df[\"Mask Score\"].max() * 6\n",
    "\n",
    "# Create heat layer\n",
    "heat_layer = gmaps.heatmap_layer(locations, weights = mask_score, max_intensity = max_intensity, dissipating = False,\n",
    "                                 point_radius = 0.8, gradient = ['white', 'blue'])\n",
    "\n",
    "# Add layer\n",
    "fig.add_layer(heat_layer)\n",
    "\n",
    "# Display figure\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emerson's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aleena's code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GBDf\n",
    "columnNames = [\"FIPS\", \"County\", \"State\", \"Pop\", \"PopDens\", \"MskScore\", \"CaseRate\", \"DeathRate\"]\n",
    "GBDf = pd.DataFrame(columns = columnNames)\n",
    "# placeholderData = [\"01001\", \"Autauga\", \"Alabama\", \"55869\", \"94.0\", \"7.51\", \"0\", \"1335\", \"32\"]\n",
    "placeholderData = {\"FIPS\":\"01001\", \"County\":\"Autauga\", \"State\":\"Alabama\", \"Pop\":55869, \"PopDens\":94.0, \"MskScore\":7.51, \"CaseRate\":1335, \"DeathRate\":32}\n",
    "GBDf = GBDf.append(placeholderData, ignore_index = True)\n",
    "GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert caseData FIPS values from float to int\n",
    "GBDf.FIPS = GBDf.FIPS.astype(np.int64)\n",
    "GBDf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GBDf DataFrame with reorganized_final_merged_caseData Dataframe\n",
    "GBDf = pd.merge(reorganized_final_merged_caseData, GBDf, how = \"left\", left_on = \"FIPS\", right_on = \"FIPS\", on = None, sort = False, copy = True, indicator = False, validate = None)\n",
    "GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate and/or irrelevant columns\n",
    "GBDf.drop(columns = [\"Date\", \"SQMI\", \"Cases\", \"Deaths\", \"County_y\", \"State_y\", \"Pop\", \"PopDens_y\", \"MskScore\",\n",
    "                     \"CaseRate_y\", \"DeathRate_y\"], inplace = True)\n",
    "GBDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "GBDf = GBDf.rename(columns = {\"County_x\":\"County\", \"State_x\":\"State\", \"PopEst\":\"Pop\", \"PopDens_x\":\"PopDens\",\n",
    "                              \"CaseRate_x\":\"CaseRate\", \"DeathRate_x\":\"DeathRate\"})\n",
    "GBDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to hold mask score from mask score DataFrame\n",
    "mskScore = merged_df[\"Mask Score\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to hold mask score\n",
    "GBDf[\"MskScore\"] = mskScore\n",
    "GBDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns\n",
    "GBDf = GBDf[[\"FIPS\", \"County\", \"State\", \"Pop\", \"PopDens\", \"MskScore\", \"CaseRate\", \"DeathRate\"]]\n",
    "GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBDf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create formatted/clean dataframe to hold values from GBDf\n",
    "formatted_GBDf = GBDf[[\"FIPS\",\"County\",\"State\",\"Pop\",\"PopDens\", \"MskScore\", \"CaseRate\", \"DeathRate\"]].copy()\n",
    "formatted_GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_GBDf = formatted_GBDf.sort_values(\"FIPS\", ascending = True)\n",
    "formatted_GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "formatted_GBDf.reset_index(drop = True, inplace = True)\n",
    "formatted_GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GBDf values to strings for cleaner formatted display\n",
    "formatted_GBDf[\"Pop\"] = formatted_GBDf[\"Pop\"].map(\"{:,}\".format)\n",
    "formatted_GBDf[\"PopDens\"] = formatted_GBDf[\"PopDens\"].map(\"{:,.2f}\".format)\n",
    "formatted_GBDf[\"MskScore\"] = formatted_GBDf[\"MskScore\"].map(\"{:,.2f}\".format)\n",
    "formatted_GBDf[\"CaseRate\"] = formatted_GBDf[\"CaseRate\"].map(\"{:,.2f}\".format)\n",
    "formatted_GBDf[\"DeathRate\"] = formatted_GBDf[\"DeathRate\"].map(\"{:,.2f}\".format)\n",
    "formatted_GBDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "formatted_GBDf.to_csv(\"formatted_GBDf.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. Mask Score vs. Population Density (with linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do areas of higher population density have higher mask scores?\n",
    "\n",
    "# Retrieve mask score and population density data\n",
    "mskScore = GBDf[\"MskScore\"]\n",
    "popDens = GBDf[\"PopDens\"]\n",
    "n = len(GBDf)\n",
    "\n",
    "# Perform a linear regression on population density versus mask scores\n",
    "slope, int, r, p, std_err = st.linregress(popDens, mskScore)\n",
    "\n",
    "# Create equation of line to calculate predicted mask scores\n",
    "fit = slope * popDens + int\n",
    "\n",
    "# Create equation in string formats to print on scatter plot\n",
    "equation = \"y = \" + str(round(slope, 2)) + \"x + \" + str(round(int, 2))\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# Plot x and y values on scatter plot\n",
    "plt.scatter(popDens, mskScore, marker=\".\", color=\"black\")\n",
    "\n",
    "# Plot linear regression line on scatter plot\n",
    "plt.plot(popDens, fit, \"--\", color = \"red\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(equation, (2500, 7), fontsize = 14, color = \"red\")\n",
    "\n",
    "# Define scatter plot title date, and x and y labels (and their font sizes)\n",
    "# medPopDens = GBDf[\"PopDens\"].median()\n",
    "\n",
    "plt.title(f\"Mask Scores vs. Population Density\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.xlabel(\"Population Density\", fontsize = 18)\n",
    "plt.ylabel(\"Mask Score\", fontsize = 18)\n",
    "plt.xlim(0, 28000)\n",
    "plt.ylim(3,10)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "print(f\"The r-value is: {r}\")\n",
    "plt.savefig(\"MaskWearingVsPopDensity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but zoomed in\n",
    "# Do areas of higher population density have higher mask scores?\n",
    "\n",
    "# Retrieve mask score and population density data\n",
    "mskScore = GBDf[\"MskScore\"]\n",
    "popDens = GBDf[\"PopDens\"]\n",
    "n = len(GBDf)\n",
    "\n",
    "# Perform a linear regression on population density versus mask scores\n",
    "slope, int, r, p, std_err = st.linregress(popDens, mskScore)\n",
    "\n",
    "# Create equation of line to calculate predicted mask scores\n",
    "fit = slope * popDens + int\n",
    "\n",
    "# Create equation in string formats to print on scatter plot\n",
    "equation = \"y = \" + str(round(slope, 4)) + \"x + \" + str(round(int, 4))\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# Plot x and y values on scatter plot\n",
    "plt.scatter(popDens, mskScore, marker=\".\", color=\"black\")\n",
    "\n",
    "# Plot linear regression line on scatter plot\n",
    "plt.plot(popDens, fit, \"--\", color = \"red\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(equation, (1750, 6.5), fontsize = 14, color = \"red\")\n",
    "\n",
    "# Define scatter plot title date, and x and y labels (and their font sizes)\n",
    "medPopDens = GBDf[\"PopDens\"].median()\n",
    "\n",
    "plt.title(f\"Mask Scores vs. Population Density\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.xlabel(\"Population Density\", fontsize = 18)\n",
    "plt.ylabel(\"Mask Score\", fontsize = 18)\n",
    "plt.xlim(0, 3000)\n",
    "plt.ylim(3,10)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "print(f\"The r-value is: {r}\")\n",
    "plt.savefig(\"ZOOMEDMaskWearingVsPopDensity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aleena's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paul's code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative COVID case rate per 100,000 population vs. Population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pair of scatterplots for case rate vs population density\n",
    "# The proper form for a graph title is \"y-axis variable vs. x-axis variable,\" so:\n",
    "# case rate vs population density and\n",
    "# death rate vs population density\n",
    "# independent variable goes on the x-axis: population density\n",
    "#   dependent variable goes on the y-axis: COVID case and death rates\n",
    "\n",
    "# Set x values to be used in both scatterplots\n",
    "n = len(GBDf)\n",
    "xValues = GBDf.loc[:, \"PopDens\"]\n",
    "CyValues = GBDf.loc[:, \"CaseRate\"]\n",
    "DyValues = GBDf.loc[:, \"DeathRate\"]\n",
    "print(f\"max. pop. dens. (x): {max(xValues)}\")\n",
    "print(f\"max. cases (Cy): {max(CyValues)}\")\n",
    "print(f\"max. deaths (Dy): {max(DyValues)}\")\n",
    "\n",
    "# Set width of x axis and height of y axis in both graphs\n",
    "xLimMax = 28000\n",
    "CyLimMax = 20000\n",
    "DyLimMax = 400\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# plot cases (C)\n",
    "plt.title(f\"COVID-19 Cases vs. Population Density\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.scatter(xValues, CyValues, marker = \".\", color = \"black\")\n",
    "plt.xlim(0, xLimMax)\n",
    "plt.ylim(0, CyLimMax)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "# now do linear regression\n",
    "(Cslope, Cintercept, Crvalue, Cpvalue, Cstderr) = linregress(xValues, CyValues)\n",
    "Cline_eq = \"y = \" + str(round(Cslope,2)) + \"x + \" + str(round(Cintercept,2))\n",
    "plt.xlabel(f\"Population Density (people per square mile)\", fontsize = 18)\n",
    "plt.ylabel(f\"Cumulative Cases per 100,000 pop.\", fontsize = 18)\n",
    "Cregress_values = np.asarray(Cslope) * xValues + Cintercept\n",
    "plt.plot(xValues,Cregress_values,\"r-\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(Cline_eq, (15000, 5000), fontsize = 14, color = \"red\")\n",
    "\n",
    "plt.savefig(\"PopDensVsCOVIDCaseRate.png\")\n",
    "print(f\"The r-value is: {Crvalue}\")\n",
    "print(f\"case slope: {Cslope}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but zoomed in\n",
    "# Create a pair of scatterplots for case rate vs population density\n",
    "# The proper form for a graph title is \"y-axis variable vs. x-axis variable,\" so:\n",
    "# case rate vs population density and\n",
    "# death rate vs population density\n",
    "# independent variable goes on the x-axis: population density\n",
    "#   dependent variable goes on the y-axis: COVID case and death rates\n",
    "\n",
    "# Set x values to be used in both scatterplots\n",
    "n = len(GBDf)\n",
    "xValues = GBDf.loc[:, \"PopDens\"]\n",
    "CyValues = GBDf.loc[:, \"CaseRate\"]\n",
    "DyValues = GBDf.loc[:, \"DeathRate\"]\n",
    "print(f\"max. pop. dens. (x): {max(xValues)}\")\n",
    "print(f\"max. cases (Cy): {max(CyValues)}\")\n",
    "print(f\"max. deaths (Dy): {max(DyValues)}\")\n",
    "\n",
    "# Set width of x axis and height of y axis in both graphs\n",
    "xLimMax = 5000\n",
    "CyLimMax = 5000\n",
    "DyLimMax = 400\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# plot cases (C)\n",
    "plt.title(f\"COVID-19 Cases vs. Population Density\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.scatter(xValues, CyValues, marker = \".\", color = \"black\")\n",
    "plt.xlim(0, xLimMax)\n",
    "plt.ylim(0, CyLimMax)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "# now do linear regression\n",
    "(Cslope, Cintercept, Crvalue, Cpvalue, Cstderr) = linregress(xValues, CyValues)\n",
    "Cline_eq = \"y = \" + str(round(Cslope,2)) + \"x + \" + str(round(Cintercept,2))\n",
    "plt.xlabel(f\"Population Density (people per square mile)\", fontsize = 18)\n",
    "plt.ylabel(f\"Cumulative Cases per 100,000 pop.\", fontsize = 18)\n",
    "Cregress_values = np.asarray(Cslope) * xValues + Cintercept\n",
    "plt.plot(xValues,Cregress_values,\"r-\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(Cline_eq, (3000, 2000), fontsize = 14, color = \"red\")\n",
    "\n",
    "plt.savefig(\"ZOOMEDPopDensVsCOVIDCaseRate.png\")\n",
    "print(f\"The r-value is: {Crvalue}\")\n",
    "print(f\"case slope: {Cslope}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative COVID death rate per 100,000 population vs. Population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pair of scatterplots for case rate vs population density\n",
    "# The proper form for a graph title is \"y-axis variable vs. x-axis variable,\" so:\n",
    "# case rate vs population density and\n",
    "# death rate vs population density\n",
    "# independent variable goes on the x-axis: population density\n",
    "#   dependent variable goes on the y-axis: COVID case and death rates\n",
    "\n",
    "# Set x values to be used in both scatterplots\n",
    "n = len(GBDf)\n",
    "xValues = GBDf.loc[:, \"PopDens\"]\n",
    "CyValues = GBDf.loc[:, \"CaseRate\"]\n",
    "DyValues = GBDf.loc[:, \"DeathRate\"]\n",
    "print(f\"max. pop. dens. (x): {max(xValues)}\")\n",
    "print(f\"max. cases (Cy): {max(CyValues)}\")\n",
    "print(f\"max. deaths (Dy): {max(DyValues)}\")\n",
    "\n",
    "# Set width of x axis and height of y axis in both graphs\n",
    "xLimMax = 28000\n",
    "CyLimMax = 5000\n",
    "DyLimMax = 400\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# plot cases (C)\n",
    "plt.title(f\"COVID-19 Deaths vs. Population Density\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.scatter(xValues, DyValues, marker = \".\", color = \"black\")\n",
    "plt.xlim(0, xLimMax)\n",
    "plt.ylim(0, DyLimMax)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "# now do linear regression\n",
    "(Dslope, Dintercept, Drvalue, Dpvalue, Dstderr) = linregress(xValues, DyValues)\n",
    "Dline_eq = \"y = \" + str(round(Dslope,2)) + \"x + \" + str(round(Dintercept,2))\n",
    "plt.xlabel(f\"Population Density (people per square mile)\", fontsize = 18)\n",
    "plt.ylabel(f\"Cumulative Deaths per 100,000 pop.\", fontsize = 18)\n",
    "Dregress_values = np.asarray(Dslope) * xValues + Dintercept\n",
    "plt.plot(xValues,Dregress_values,\"r-\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(Dline_eq, (15000, 100), fontsize = 14, color = \"red\")\n",
    "\n",
    "plt.savefig(\"PopDensVsCOVIDDeathRate.png\")\n",
    "print(f\"The r-value is: {Drvalue}\")\n",
    "print(f\"case slope: {Dslope}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplots for death rate vs case rate\n",
    "# The proper form for a graph title is \"y-axis variable vs. x-axis variable,\" so:\n",
    "# death rate vs case rate\n",
    "# independent variable goes on the x-axis: case rate\n",
    "#   dependent variable goes on the y-axis: death rate\n",
    "\n",
    "# Set x values to be used in both scatterplots\n",
    "n = len(GBDf)\n",
    "xValues = GBDf.loc[:, \"CaseRate\"]\n",
    "yValues = GBDf.loc[:, \"DeathRate\"]\n",
    "print(f\"max. cases (x): {max(xValues)}\")\n",
    "print(f\"max. deaths (y): {max(yValues)}\")\n",
    "\n",
    "# Set axis limits in both graphs (shared y)\n",
    "xLimMax = 15000\n",
    "yLimMax = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative COVID case rate per 100,000 population vs. Mask-wearing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot for case rate vs mask-wearing score\n",
    "# The proper form for a graph title is \"y-axis variable vs. x-axis variable,\" so:\n",
    "# case rate vs population density and\n",
    "# death rate vs population density\n",
    "# independent variable goes on the x-axis: mask-wearing score\n",
    "#   dependent variable goes on the y-axis: COVID case and death rates\n",
    "\n",
    "# Set x and y values\n",
    "n = len(GBDf)\n",
    "xValues = GBDf.loc[:, \"MskScore\"]\n",
    "CyValues = GBDf.loc[:, \"CaseRate\"]\n",
    "DyValues = GBDf.loc[:, \"DeathRate\"]\n",
    "print(f\"max. mask score (x): {max(xValues)}\")\n",
    "print(f\"max. cases (Cy): {max(CyValues)}\")\n",
    "print(f\"max. deaths (Dy): {max(DyValues)}\")\n",
    "\n",
    "# Set width of x axis and height of y axis in both graphs\n",
    "xLimMax = 10\n",
    "CyLimMax = 20000\n",
    "DyLimMax = 400\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# plot cases (C)\n",
    "plt.title(f\"COVID-19 Cases vs. Mask Wearing Score\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.scatter(xValues, CyValues, marker = \".\", color = \"black\")\n",
    "plt.xlim(2, xLimMax)\n",
    "plt.ylim(0, CyLimMax)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "# now do linear regression\n",
    "(Cslope, Cintercept, Crvalue, Cpvalue, Cstderr) = linregress(xValues, CyValues)\n",
    "Cline_eq = \"y = \" + str(round(Cslope,2)) + \"x + \" + str(round(Cintercept,2))\n",
    "plt.xlabel(f\"Mask Wearing Score\", fontsize = 18)\n",
    "plt.ylabel(f\"Cumulative Cases per 100,000 pop.\", fontsize = 18)\n",
    "Cregress_values = np.asarray(Cslope) * xValues + Cintercept\n",
    "plt.plot(xValues,Cregress_values,\"r-\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(Cline_eq, (3, 5000), fontsize = 14, color = \"red\")\n",
    "\n",
    "plt.savefig(\"MaskWearingVsCOVIDCaseRate.png\")\n",
    "print(f\"The r-value is: {Crvalue}\")\n",
    "print(f\"case slope: {Cslope}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative COVID death rate per 100,000 population vs. Population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot for death rate vs mask-wearing score\n",
    "# The proper form for a graph title is \"y-axis variable vs. x-axis variable,\" so:\n",
    "# case rate vs population density and\n",
    "# death rate vs population density\n",
    "# independent variable goes on the x-axis: mask-wearing score\n",
    "#   dependent variable goes on the y-axis: COVID death rates\n",
    "\n",
    "# Set x and y values\n",
    "xValues = GBDf.loc[:, \"MskScore\"]\n",
    "yValues = GBDf.loc[:, \"DeathRate\"]\n",
    "print(f\"max. mask score (1) (x): {max(xValues)}\")\n",
    "print(f\"max. deaths (Dy): {max(yValues)}\")\n",
    "\n",
    "# Set width of x axis and height of y axis in both graphs\n",
    "xLimMax = 10\n",
    "CyLimMax = 15000\n",
    "DyLimMax = 400\n",
    "\n",
    "# Define scatter plot size\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "# plot deaths (D)\n",
    "plt.title(f\"COVID-19 Deaths vs. Mask Wearing Score\\nby county as of July 14, 2020 (n={n})\", fontsize = 20)\n",
    "plt.scatter(xValues, yValues, marker = \".\", color = \"black\")\n",
    "plt.xlim(2, xLimMax)\n",
    "plt.ylim(0, yLimMax)\n",
    "plt.grid(axis = \"x\", linewidth = 0.5)\n",
    "plt.grid(axis = \"y\", linewidth = 0.5)\n",
    "\n",
    "# now do linear regression\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(xValues, yValues)\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.xlabel(f\"Mask Wearing Score\", fontsize = 18)\n",
    "plt.ylabel(f\"Cumulative Deaths per 100,000 pop.\", fontsize = 18)\n",
    "regress_values = np.asarray(slope) * xValues + intercept\n",
    "plt.plot(xValues,regress_values,\"r-\")\n",
    "\n",
    "# Define linear regression line and print on scatter plot\n",
    "plt.annotate(line_eq, (3, 100), fontsize = 14, color = \"red\")\n",
    "\n",
    "plt.savefig(\"MaskWearingVsCOVIDDeathRate.png\")\n",
    "print(f\"The r-value is: {rvalue}\")\n",
    "print(f\"death slope: {slope}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paul's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
